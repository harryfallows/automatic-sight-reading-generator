{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Evaluation\n",
    "===============\n",
    "This notebook produces the data analysis graphics of the pieces generated by a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from music21 import corpus, converter, instrument, note, chord, stream, pitch, key\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from preprocessing import read_mxl, get_notes\n",
    "import pandas as pd\n",
    "from fractions import Fraction\n",
    "import os\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "from statistics import mean\n",
    "from PIL import Image\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_dataset = '../../example_models/notes_slurs_dynamics_spanners_articulations_text-expressions'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def items_in_pieces(pieces, all_pitches, all_quarterLengths):\n",
    "    pitches_in_pieces = {}\n",
    "    qls_in_pieces = {}\n",
    "    for k,p in pieces.items():\n",
    "        pitches_in_p = []\n",
    "        qls_in_p = []\n",
    "        for n in p:\n",
    "            pitches_in_p.append(n[0])\n",
    "            qls_in_p.append(n[1])\n",
    "        pitches_in_pieces.update({k:pitches_in_p})\n",
    "        qls_in_pieces.update({k:qls_in_p})\n",
    "    return frequencies_of_items(pitches_in_pieces, all_pitches), frequencies_of_items(qls_in_pieces, all_quarterLengths)\n",
    "\n",
    "def frequencies_of_items(num_in_pieces, all_items):\n",
    "    df_item_frequencies = pd.DataFrame(columns = [\"file\"] + list(all_items))\n",
    "    for k,p in num_in_pieces.items():\n",
    "        df_row = [k]\n",
    "        for pi in df_item_frequencies.iteritems():\n",
    "            if pi[0] == \"file\":\n",
    "                continue\n",
    "            freq_item = p.count(pi[0])\n",
    "            df_row.append(freq_item)\n",
    "        df_item_frequencies = df_item_frequencies.append(pd.Series(df_row, index=df_item_frequencies.columns), ignore_index=True)\n",
    "\n",
    "    return df_item_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sum_df_frequencies(df_pitch_frequencies):\n",
    "    return df_pitch_frequencies.drop(\"file\", axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_generation_types(gt_frequencies):\n",
    "    return pd.concat(gt_frequencies, axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams.update({'font.size': 40})\n",
    "def pitches_per_piece(df_pitch_frequencies):\n",
    "    return df_pitch_frequencies.astype(bool).sum(axis=1)\n",
    "def produce_graphs(dataset):\n",
    "    pitch_freq_series = []\n",
    "    so_pitch_freq_series = []\n",
    "    ql_freq_series = []\n",
    "    gen_techs = []\n",
    "    counted_acc_per_gen_tech = {}\n",
    "    counted_pitches_per_gen_tech = {}\n",
    "    counted_pitches_per_piece = []\n",
    "    counted_accidentals = []\n",
    "    mean_pitches_per_piece = []\n",
    "    mean_accidentals = []\n",
    "    for i, piece_folder in enumerate(os.listdir(dataset)+['abrsm_grade_5_violin/data']):\n",
    "        full_folder_name = dataset+\"/\"+piece_folder if piece_folder != 'abrsm_grade_5_violin/data' else piece_folder\n",
    "        if not os.path.isdir(full_folder_name):\n",
    "            continue\n",
    "        gen_techs.append(piece_folder)\n",
    "        parts_paths, time_signatures, key_signatures, files = read_mxl(full_folder_name)\n",
    "        accidentals = get_accidentals(parts_paths, key_signatures)\n",
    "        mean_accidentals.append(mean(accidentals))\n",
    "        counted_accidentals.append(accidentals)\n",
    "        counted_acc_per_gen_tech[piece_folder] = {name:acc for name,acc in zip(files, accidentals)}\n",
    "        pieces, all_pitches, all_quarterLengths = get_notes(parts_paths, single_octave=False)\n",
    "        so_pieces, so_all_pitches, _ = get_notes(parts_paths, single_octave=True)\n",
    "        pieces = {f:p for f, p in zip(files, pieces)}\n",
    "        so_pieces = {f:p for f, p in zip(files, so_pieces)}\n",
    "        df_pitch_frequencies, df_ql_frequencies = items_in_pieces(pieces, all_pitches, all_quarterLengths)\n",
    "        df_so_pitch_frequencies, _ = items_in_pieces(so_pieces, so_all_pitches, all_quarterLengths)\n",
    "        pitches_per_piece = df_pitch_frequencies.astype(bool).sum(axis=1)\n",
    "        counted_pitches_per_gen_tech[piece_folder] = {name:acc for name,acc in zip(files, pitches_per_piece)}\n",
    "        counted_pitches_per_piece.append(pitches_per_piece)\n",
    "        mean_pitches_per_piece.append(pitches_per_piece.mean())\n",
    "        pitch_series = sum_df_frequencies(df_pitch_frequencies)\n",
    "        pitch_series = pitch_series.div(pitch_series.sum())\n",
    "        pitch_freq_series.append(pitch_series)\n",
    "        so_pitch_series = sum_df_frequencies(df_so_pitch_frequencies)\n",
    "        so_pitch_series = so_pitch_series.div(so_pitch_series.sum())\n",
    "        so_pitch_freq_series.append(so_pitch_series)\n",
    "        ql_series = sum_df_frequencies(df_ql_frequencies)\n",
    "        ql_series = ql_series.div(ql_series.sum())\n",
    "        ql_freq_series.append(ql_series)\n",
    "    \n",
    "\n",
    "    plot_freq_dist(pitch_freq_series, gen_techs)\n",
    "    plt.title(\"Pitch Frequency Analysis\")\n",
    "    plt.savefig(dataset+\"/pitch_frequency_analysis.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.bar(gen_techs, mean_pitches_per_piece, align='center')\n",
    "    plt.title(\"Mean Number of Pitches Per Piece\")\n",
    "    plt.savefig(dataset+\"/mean_pitches_per_piece.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    plt.bar(gen_techs, mean_accidentals, align='center')\n",
    "    plt.title(\"Mean Number of Accidentals Per Piece\")\n",
    "    plt.savefig(dataset+\"/mean_accidentals_per_piece.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    useful_plots = []\n",
    "    \n",
    "    plot_freq_dist(so_pitch_freq_series, gen_techs)\n",
    "    plt.title(\"Pitch Frequency Analysis Single Octave\")\n",
    "    plt.savefig(dataset+\"/pitch_frequency_analysis_single_octave.png\")\n",
    "    useful_plots.append(dataset+\"/pitch_frequency_analysis_single_octave.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    plot_freq_dist(ql_freq_series, gen_techs)\n",
    "    plt.title(\"Note Length Frequency Analysis\")\n",
    "    plt.savefig(dataset+\"/ql_frequency_analysis.png\")\n",
    "    useful_plots.append(dataset+\"/ql_frequency_analysis.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    ls = dict(linewidth=4.0, color='black')\n",
    "    ml = dict(linewidth=4.0, color='orange')\n",
    "    meanl = dict(linewidth=4.0, color='blue')\n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "    ax.set_title('Box Plot Showing The Distribution of Accidentals Accross The Generated Pieces')\n",
    "    ax.boxplot(counted_accidentals, labels=gen_techs, boxprops=ls , whiskerprops=ls, capprops=ls, flierprops=ls, medianprops=ml, meanprops=meanl, meanline=True, showmeans=True)\n",
    "    plt.savefig(dataset+\"/accidentals_per_piece.png\")\n",
    "    useful_plots.append(dataset+\"/accidentals_per_piece.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "    ax.set_title('Box Plot Showing The Distribution of Pitches Accross The Generated Pieces')\n",
    "    ax.boxplot(counted_pitches_per_piece, labels=gen_techs, boxprops=ls, whiskerprops=ls, capprops=ls, flierprops=ls, medianprops=ml, meanprops=meanl, meanline=True, showmeans=True)\n",
    "    plt.savefig(dataset+\"/pitches_per_piece.png\")\n",
    "    useful_plots.append(dataset+\"/pitches_per_piece.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "    useful_plots_opened = [Image.open(p) for p in useful_plots]\n",
    "    widths, heights = zip(*(i.size for i in useful_plots_opened))\n",
    "    width = max(widths)\n",
    "    height = max(heights)\n",
    "    useful_plots_image = Image.new('RGB', (width*2, height*2))\n",
    "    \n",
    "    useful_plots_image.paste(useful_plots_opened[0], (0,0))\n",
    "    useful_plots_image.paste(useful_plots_opened[1], (width,0))\n",
    "    useful_plots_image.paste(useful_plots_opened[2], (0,height))\n",
    "    useful_plots_image.paste(useful_plots_opened[3], (width,height))\n",
    "    useful_plots_image.save(dataset+'/useful_plots.png')\n",
    "    \n",
    "    return counted_acc_per_gen_tech, counted_accidentals[-1], counted_pitches_per_gen_tech, counted_pitches_per_piece[-1]\n",
    "    \n",
    "def plot_freq_dist(freq_series, gen_techs):\n",
    "    transposed_df = concat_generation_types(freq_series)\n",
    "    column_names = {i:g for i,g in enumerate(gen_techs)}\n",
    "    transposed_df = transposed_df.rename(columns = {i:g for i,g in enumerate(gen_techs)})\n",
    "    width = 30\n",
    "    if len(transposed_df) > 20:\n",
    "        width = 100\n",
    "    transposed_df.plot.bar(rot=0, figsize=(width,30))\n",
    "    \n",
    "\n",
    "def get_accidentals(parts_paths, key_signatures):\n",
    "    pieces, _, _ = get_notes(parts_paths, single_octave=True)\n",
    "    counted_accidentals = []\n",
    "    for p, k in zip(pieces, key_signatures):\n",
    "        key_object = key.KeySignature(k).getScale(\"major\")\n",
    "        notes_in_key = list(set([str(p)[:-1] for p in key_object.getPitches()]))\n",
    "        all_pitches = [n[0] for n in p]\n",
    "        all_accidentals = [p for p in all_pitches if p not in notes_in_key+[\"Rest\"]]\n",
    "        counted_accidentals.append(len(all_accidentals))\n",
    "    return counted_accidentals\n",
    "\n",
    "for i, piece_folder in enumerate(os.listdir(grid_search_dataset)):\n",
    "    full_folder_name = \"{}/test_results\".format(grid_search_dataset, piece_folder)\n",
    "    print(full_folder_name)\n",
    "    if os.path.isdir(full_folder_name):\n",
    "        for loss_val_loss in [\"loss\",\"val_loss\"]:\n",
    "            print(\"{}/{}/generated_scores\".format(full_folder_name, loss_val_loss))\n",
    "            produce_graphs(\"{}/{}/generated_scores\".format(full_folder_name, loss_val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
