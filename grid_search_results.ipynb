{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search Results\n",
    "================\n",
    "Displays the results of grid searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"\" #folder containin models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "for i, file in enumerate(os.listdir(folder)):\n",
    "    if file[0] == \".\":\n",
    "        continue\n",
    "    try:\n",
    "        test_results.append(pickle.load(open(\"{}/test_results/test_results.pickle\".format(folder+\"/\"+file), \"rb\")))\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "print(len(test_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results = pd.concat(test_results, axis=1).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch</th>\n",
       "      <th>val_loss_epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>training_time</th>\n",
       "      <th>folder_name_prefix</th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lstm_layers</th>\n",
       "      <th>single_loss_function</th>\n",
       "      <th>multi_loss_function</th>\n",
       "      <th>optimiser</th>\n",
       "      <th>epochs</th>\n",
       "      <th>last_layer_inputs</th>\n",
       "      <th>test_loss_loss</th>\n",
       "      <th>test_loss_categorical_accuracy</th>\n",
       "      <th>test_val_loss_loss</th>\n",
       "      <th>test_val_loss_categorical_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.680145</td>\n",
       "      <td>0.676963</td>\n",
       "      <td>0.186522</td>\n",
       "      <td>0.202412</td>\n",
       "      <td>1655.73</td>\n",
       "      <td>babies</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.665302</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.665302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>0.82039</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.548099</td>\n",
       "      <td>1.11664</td>\n",
       "      <td>8219.02</td>\n",
       "      <td>locomotive</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2495</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>1.1555</td>\n",
       "      <td>0.661206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.660602</td>\n",
       "      <td>0.664682</td>\n",
       "      <td>0.200079</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>2717.54</td>\n",
       "      <td>blasts</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218776</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.218776</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.648178</td>\n",
       "      <td>0.66431</td>\n",
       "      <td>1.24743</td>\n",
       "      <td>1.1673</td>\n",
       "      <td>673.535</td>\n",
       "      <td>occasions</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.22061</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.21874</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>0.639663</td>\n",
       "      <td>0.658355</td>\n",
       "      <td>0.236961</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>728.228</td>\n",
       "      <td>boosts</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.22901</td>\n",
       "      <td>0.645197</td>\n",
       "      <td>0.228509</td>\n",
       "      <td>0.649293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.813643</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.0785895</td>\n",
       "      <td>0.204033</td>\n",
       "      <td>8140.34</td>\n",
       "      <td>stencils</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>0.648548</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.656366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.645526</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>1.25189</td>\n",
       "      <td>1.17244</td>\n",
       "      <td>700.752</td>\n",
       "      <td>manufacturers</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.22251</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.22251</td>\n",
       "      <td>0.650782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.61663</td>\n",
       "      <td>0.653517</td>\n",
       "      <td>0.260641</td>\n",
       "      <td>0.234228</td>\n",
       "      <td>1097.59</td>\n",
       "      <td>exercises</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.245478</td>\n",
       "      <td>0.637007</td>\n",
       "      <td>0.24638</td>\n",
       "      <td>0.639613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.678517</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.188837</td>\n",
       "      <td>0.202743</td>\n",
       "      <td>1699.03</td>\n",
       "      <td>definition</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212569</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.212747</td>\n",
       "      <td>0.661206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.641059</td>\n",
       "      <td>0.660588</td>\n",
       "      <td>1.29332</td>\n",
       "      <td>1.22162</td>\n",
       "      <td>1065.35</td>\n",
       "      <td>courtesy</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.26739</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>1.26313</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.628775</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>0.22813</td>\n",
       "      <td>1118.41</td>\n",
       "      <td>neutrons</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.650782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>0.679819</td>\n",
       "      <td>0.663937</td>\n",
       "      <td>0.180696</td>\n",
       "      <td>0.20642</td>\n",
       "      <td>2540.7</td>\n",
       "      <td>gold</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216906</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>0.218087</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.637383</td>\n",
       "      <td>0.655378</td>\n",
       "      <td>1.32786</td>\n",
       "      <td>1.2508</td>\n",
       "      <td>1064.19</td>\n",
       "      <td>objectives</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.30223</td>\n",
       "      <td>0.646314</td>\n",
       "      <td>1.30223</td>\n",
       "      <td>0.646314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.676004</td>\n",
       "      <td>0.66431</td>\n",
       "      <td>1.07857</td>\n",
       "      <td>1.12236</td>\n",
       "      <td>2595.09</td>\n",
       "      <td>cleanser</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17487</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.17523</td>\n",
       "      <td>0.654877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.831092</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>1.11164</td>\n",
       "      <td>7981.57</td>\n",
       "      <td>dangers</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.29186</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>1.15993</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>0.767298</td>\n",
       "      <td>0.688128</td>\n",
       "      <td>0.70721</td>\n",
       "      <td>1.09425</td>\n",
       "      <td>5225.05</td>\n",
       "      <td>respects</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15288</td>\n",
       "      <td>0.684289</td>\n",
       "      <td>1.13296</td>\n",
       "      <td>0.667908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.624261</td>\n",
       "      <td>0.654261</td>\n",
       "      <td>1.4138</td>\n",
       "      <td>1.26612</td>\n",
       "      <td>1053.15</td>\n",
       "      <td>thermals</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.31771</td>\n",
       "      <td>0.641474</td>\n",
       "      <td>1.31771</td>\n",
       "      <td>0.641474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>1.01041</td>\n",
       "      <td>1.13152</td>\n",
       "      <td>2551.2</td>\n",
       "      <td>overcoats</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17482</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>1.1881</td>\n",
       "      <td>0.659345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>0.655809</td>\n",
       "      <td>0.662449</td>\n",
       "      <td>1.19579</td>\n",
       "      <td>1.14602</td>\n",
       "      <td>698.305</td>\n",
       "      <td>milligram</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.19956</td>\n",
       "      <td>0.656739</td>\n",
       "      <td>1.20371</td>\n",
       "      <td>0.656366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.657671</td>\n",
       "      <td>0.661332</td>\n",
       "      <td>1.18994</td>\n",
       "      <td>1.15157</td>\n",
       "      <td>689.051</td>\n",
       "      <td>extenuations</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.20485</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>1.20485</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.702341</td>\n",
       "      <td>0.684034</td>\n",
       "      <td>0.96462</td>\n",
       "      <td>1.09052</td>\n",
       "      <td>1647.12</td>\n",
       "      <td>beginners</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15033</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>1.15033</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0.687218</td>\n",
       "      <td>0.673986</td>\n",
       "      <td>0.173029</td>\n",
       "      <td>0.200768</td>\n",
       "      <td>1652.37</td>\n",
       "      <td>trusts</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212168</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.210386</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.664325</td>\n",
       "      <td>0.66952</td>\n",
       "      <td>0.19427</td>\n",
       "      <td>0.203925</td>\n",
       "      <td>2593.95</td>\n",
       "      <td>influence</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.219316</td>\n",
       "      <td>0.654877</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>0.654505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>0.766414</td>\n",
       "      <td>0.681057</td>\n",
       "      <td>0.10742</td>\n",
       "      <td>0.196906</td>\n",
       "      <td>8764.39</td>\n",
       "      <td>hitches</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218377</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>0.209289</td>\n",
       "      <td>0.662323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777628</td>\n",
       "      <td>0.682173</td>\n",
       "      <td>0.676739</td>\n",
       "      <td>1.08384</td>\n",
       "      <td>8226.69</td>\n",
       "      <td>modem</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.18807</td>\n",
       "      <td>0.663812</td>\n",
       "      <td>1.15028</td>\n",
       "      <td>0.659717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.802615</td>\n",
       "      <td>0.66952</td>\n",
       "      <td>0.0835701</td>\n",
       "      <td>0.201177</td>\n",
       "      <td>5495.6</td>\n",
       "      <td>guilt</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.221225</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>0.762831</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.108168</td>\n",
       "      <td>0.200589</td>\n",
       "      <td>8184.2</td>\n",
       "      <td>door</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.21728</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.657483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.619329</td>\n",
       "      <td>0.655006</td>\n",
       "      <td>1.42453</td>\n",
       "      <td>1.28034</td>\n",
       "      <td>1070.94</td>\n",
       "      <td>submarine</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.32622</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>1.32622</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.754595</td>\n",
       "      <td>0.677707</td>\n",
       "      <td>0.114805</td>\n",
       "      <td>0.202691</td>\n",
       "      <td>5178.62</td>\n",
       "      <td>quality</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.217582</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.212273</td>\n",
       "      <td>0.660834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>0.802196</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.0850274</td>\n",
       "      <td>0.203961</td>\n",
       "      <td>8655.81</td>\n",
       "      <td>workman</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.221153</td>\n",
       "      <td>0.661579</td>\n",
       "      <td>0.211517</td>\n",
       "      <td>0.653388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.640826</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.238675</td>\n",
       "      <td>0.219339</td>\n",
       "      <td>698.085</td>\n",
       "      <td>stars</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.65041</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.65041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>1.00917</td>\n",
       "      <td>1.12038</td>\n",
       "      <td>2515.74</td>\n",
       "      <td>conjunctions</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17304</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>1.17304</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>0.696059</td>\n",
       "      <td>0.675102</td>\n",
       "      <td>0.984896</td>\n",
       "      <td>1.10634</td>\n",
       "      <td>1670.66</td>\n",
       "      <td>sparks</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16172</td>\n",
       "      <td>0.656366</td>\n",
       "      <td>1.16006</td>\n",
       "      <td>0.654505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.650179</td>\n",
       "      <td>0.660216</td>\n",
       "      <td>0.226623</td>\n",
       "      <td>0.21688</td>\n",
       "      <td>731.296</td>\n",
       "      <td>update</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.651526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.776651</td>\n",
       "      <td>0.668403</td>\n",
       "      <td>0.681971</td>\n",
       "      <td>1.1056</td>\n",
       "      <td>7997.1</td>\n",
       "      <td>discontinuance</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.18782</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>1.14598</td>\n",
       "      <td>0.663068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>0.685869</td>\n",
       "      <td>0.682173</td>\n",
       "      <td>1.03609</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>1639.1</td>\n",
       "      <td>metrics</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15275</td>\n",
       "      <td>0.665302</td>\n",
       "      <td>1.1604</td>\n",
       "      <td>0.661579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>0.685589</td>\n",
       "      <td>0.671381</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>0.205003</td>\n",
       "      <td>2684.12</td>\n",
       "      <td>stop</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.213148</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>0.212067</td>\n",
       "      <td>0.655249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.798427</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.618982</td>\n",
       "      <td>1.08209</td>\n",
       "      <td>5071.45</td>\n",
       "      <td>allegations</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.67796</td>\n",
       "      <td>1.12957</td>\n",
       "      <td>0.670514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.784887</td>\n",
       "      <td>0.687756</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>1.07315</td>\n",
       "      <td>5123.47</td>\n",
       "      <td>pits</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16788</td>\n",
       "      <td>0.675354</td>\n",
       "      <td>1.13248</td>\n",
       "      <td>0.670141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>0.764692</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.109621</td>\n",
       "      <td>0.198006</td>\n",
       "      <td>5485.84</td>\n",
       "      <td>ropes</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.210654</td>\n",
       "      <td>0.663068</td>\n",
       "      <td>0.205984</td>\n",
       "      <td>0.655994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.793728</td>\n",
       "      <td>0.681801</td>\n",
       "      <td>0.62204</td>\n",
       "      <td>1.10993</td>\n",
       "      <td>5243.47</td>\n",
       "      <td>currencies</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.20454</td>\n",
       "      <td>0.662323</td>\n",
       "      <td>1.15853</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.617049</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.261387</td>\n",
       "      <td>0.234265</td>\n",
       "      <td>1074.27</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.248055</td>\n",
       "      <td>0.641847</td>\n",
       "      <td>0.248894</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.0939058</td>\n",
       "      <td>0.20267</td>\n",
       "      <td>5191.32</td>\n",
       "      <td>courtesy</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>0.6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.631055</td>\n",
       "      <td>0.65575</td>\n",
       "      <td>0.242749</td>\n",
       "      <td>0.22886</td>\n",
       "      <td>1064.7</td>\n",
       "      <td>morning</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239254</td>\n",
       "      <td>0.645197</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0.677633</td>\n",
       "      <td>0.672869</td>\n",
       "      <td>1.07388</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>2537.64</td>\n",
       "      <td>backups</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16542</td>\n",
       "      <td>0.657111</td>\n",
       "      <td>1.17307</td>\n",
       "      <td>0.657483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.643432</td>\n",
       "      <td>0.66096</td>\n",
       "      <td>0.228271</td>\n",
       "      <td>0.215703</td>\n",
       "      <td>700.107</td>\n",
       "      <td>thirteen</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.230626</td>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.230025</td>\n",
       "      <td>0.648176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.690382</td>\n",
       "      <td>0.674358</td>\n",
       "      <td>0.174754</td>\n",
       "      <td>0.19998</td>\n",
       "      <td>1767.04</td>\n",
       "      <td>color</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.679196</td>\n",
       "      <td>1.04545</td>\n",
       "      <td>1.10519</td>\n",
       "      <td>1672.15</td>\n",
       "      <td>wine</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15728</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>1.15651</td>\n",
       "      <td>0.665674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_epoch val_loss_epoch categorical_accuracy val_categorical_accuracy  \\\n",
       "0          60             60             0.680145                 0.676963   \n",
       "1          60             29              0.82039                 0.670636   \n",
       "2          60             60             0.660602                 0.664682   \n",
       "3          59             60             0.648178                  0.66431   \n",
       "4          58             60             0.639663                 0.658355   \n",
       "5          60             37             0.813643                 0.663193   \n",
       "6          60             60             0.645526                 0.656494   \n",
       "7          60             59              0.61663                 0.653517   \n",
       "8          60             57             0.678517                 0.675475   \n",
       "9          59             60             0.641059                 0.660588   \n",
       "10         59             59             0.628775                 0.656494   \n",
       "11         60             56             0.679819                 0.663937   \n",
       "12         60             60             0.637383                 0.655378   \n",
       "13         60             57             0.676004                  0.66431   \n",
       "14         60             30             0.831092                 0.675475   \n",
       "15         60             42             0.767298                 0.688128   \n",
       "16         60             60             0.624261                 0.654261   \n",
       "17         59             49             0.689219                 0.670636   \n",
       "18         58             60             0.655809                 0.662449   \n",
       "19         60             60             0.657671                 0.661332   \n",
       "20         59             59             0.702341                 0.684034   \n",
       "21         60             54             0.687218                 0.673986   \n",
       "22         60             59             0.664325                  0.66952   \n",
       "23         60             45             0.766414                 0.681057   \n",
       "24         60             36             0.777628                 0.682173   \n",
       "25         60             37             0.802615                  0.66952   \n",
       "26         60             49             0.762831                 0.668031   \n",
       "27         60             60             0.619329                 0.655006   \n",
       "28         60             34             0.754595                 0.677707   \n",
       "29         57             41             0.802196                 0.659472   \n",
       "30         59             59             0.640826                 0.659472   \n",
       "31         60             60             0.689591                 0.676591   \n",
       "32         60             53             0.696059                 0.675102   \n",
       "33         60             60             0.650179                 0.660216   \n",
       "34         60             40             0.776651                 0.668403   \n",
       "35         59             55             0.685869                 0.682173   \n",
       "36         60             58             0.685589                 0.671381   \n",
       "37         60             34             0.798427                  0.69185   \n",
       "38         60             36             0.784887                 0.687756   \n",
       "39         60             41             0.764692                 0.676591   \n",
       "40         60             34             0.793728                 0.681801   \n",
       "41         60             59             0.617049                 0.651656   \n",
       "42         60             33             0.784235                 0.665798   \n",
       "43         60             59             0.631055                  0.65575   \n",
       "44         60             54             0.677633                 0.672869   \n",
       "45         59             60             0.643432                  0.66096   \n",
       "46         60             60             0.690382                 0.674358   \n",
       "47         59             57             0.681913                 0.679196   \n",
       "\n",
       "         loss  val_loss training_time folder_name_prefix lstm_units dropout  \\\n",
       "0    0.186522  0.202412       1655.73             babies        128     0.3   \n",
       "1    0.548099   1.11664       8219.02         locomotive        256     0.2   \n",
       "2    0.200079  0.207182       2717.54             blasts        128     0.3   \n",
       "3     1.24743    1.1673       673.535          occasions         64     0.3   \n",
       "4    0.236961    0.2174       728.228             boosts         64     0.3   \n",
       "5   0.0785895  0.204033       8140.34           stencils        256     0.2   \n",
       "6     1.25189   1.17244       700.752      manufacturers         64     0.3   \n",
       "7    0.260641  0.234228       1097.59          exercises         64     0.3   \n",
       "8    0.188837  0.202743       1699.03         definition        128     0.3   \n",
       "9     1.29332   1.22162       1065.35           courtesy         64     0.2   \n",
       "10   0.244774   0.22813       1118.41           neutrons         64     0.2   \n",
       "11   0.180696   0.20642        2540.7               gold        128     0.2   \n",
       "12    1.32786    1.2508       1064.19         objectives         64     0.2   \n",
       "13    1.07857   1.12236       2595.09           cleanser        128     0.3   \n",
       "14   0.511027   1.11164       7981.57            dangers        256     0.2   \n",
       "15    0.70721   1.09425       5225.05           respects        256     0.3   \n",
       "16     1.4138   1.26612       1053.15           thermals         64     0.3   \n",
       "17    1.01041   1.13152        2551.2          overcoats        128     0.2   \n",
       "18    1.19579   1.14602       698.305          milligram         64     0.2   \n",
       "19    1.18994   1.15157       689.051       extenuations         64     0.2   \n",
       "20    0.96462   1.09052       1647.12          beginners        128     0.2   \n",
       "21   0.173029  0.200768       1652.37             trusts        128     0.2   \n",
       "22    0.19427  0.203925       2593.95          influence        128     0.3   \n",
       "23    0.10742  0.196906       8764.39            hitches        256     0.3   \n",
       "24   0.676739   1.08384       8226.69              modem        256     0.3   \n",
       "25  0.0835701  0.201177        5495.6              guilt        256     0.2   \n",
       "26   0.108168  0.200589        8184.2               door        256     0.3   \n",
       "27    1.42453   1.28034       1070.94          submarine         64     0.3   \n",
       "28   0.114805  0.202691       5178.62            quality        256     0.3   \n",
       "29  0.0850274  0.203961       8655.81            workman        256     0.2   \n",
       "30   0.238675  0.219339       698.085              stars         64     0.3   \n",
       "31    1.00917   1.12038       2515.74       conjunctions        128     0.2   \n",
       "32   0.984896   1.10634       1670.66             sparks        128     0.2   \n",
       "33   0.226623   0.21688       731.296             update         64     0.2   \n",
       "34   0.681971    1.1056        7997.1     discontinuance        256     0.3   \n",
       "35    1.03609    1.0986        1639.1            metrics        128     0.3   \n",
       "36   0.176514  0.205003       2684.12               stop        128     0.2   \n",
       "37   0.618982   1.08209       5071.45        allegations        256     0.2   \n",
       "38   0.657706   1.07315       5123.47               pits        256     0.3   \n",
       "39   0.109621  0.198006       5485.84              ropes        256     0.3   \n",
       "40    0.62204   1.10993       5243.47         currencies        256     0.2   \n",
       "41   0.261387  0.234265       1074.27        acquisition         64     0.3   \n",
       "42  0.0939058   0.20267       5191.32           courtesy        256     0.2   \n",
       "43   0.242749   0.22886        1064.7            morning         64     0.2   \n",
       "44    1.07388    1.1225       2537.64            backups        128     0.3   \n",
       "45   0.228271  0.215703       700.107           thirteen         64     0.2   \n",
       "46   0.174754   0.19998       1767.04              color        128     0.2   \n",
       "47    1.04545   1.10519       1672.15               wine        128     0.3   \n",
       "\n",
       "   lstm_layers      single_loss_function  multi_loss_function optimiser  \\\n",
       "0            2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "1            3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "2            3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "3            2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "4            2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "5            3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "6            2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "7            3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "8            2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "9            3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "10           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "11           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "12           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "13           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "14           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "15           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "16           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "17           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "18           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "19           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "20           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "21           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "22           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "23           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "24           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "25           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "26           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "27           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "28           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "29           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "30           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "31           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "32           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "33           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "34           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "35           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "36           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "37           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "38           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "39           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "40           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "41           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "42           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "43           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "44           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "45           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "46           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "47           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "\n",
       "   epochs last_layer_inputs test_loss_loss test_loss_categorical_accuracy  \\\n",
       "0      60             False       0.212126                       0.665302   \n",
       "1      60             False         1.2495                         0.6586   \n",
       "2      60             False       0.218776                       0.654133   \n",
       "3      60             False        1.22061                       0.650782   \n",
       "4      60             False        0.22901                       0.645197   \n",
       "5      60             False       0.227899                       0.648548   \n",
       "6      60             False        1.22251                       0.650782   \n",
       "7      60             False       0.245478                       0.637007   \n",
       "8      60             False       0.212569                       0.658228   \n",
       "9      60             False        1.26739                       0.650037   \n",
       "10     60             False       0.239131                       0.650782   \n",
       "11     60             False       0.216906                       0.652271   \n",
       "12     60             False        1.30223                       0.646314   \n",
       "13     60             False        1.17487                       0.650782   \n",
       "14     60             False        1.29186                       0.650037   \n",
       "15     60             False        1.15288                       0.684289   \n",
       "16     60             False        1.31771                       0.641474   \n",
       "17     60             False        1.17482                       0.664557   \n",
       "18     60             False        1.19956                       0.656739   \n",
       "19     60             False        1.20485                       0.652271   \n",
       "20     60             False        1.15033                       0.658972   \n",
       "21     60             False       0.212168                       0.655622   \n",
       "22     60             False       0.219316                       0.654877   \n",
       "23     60             False       0.218377                       0.658972   \n",
       "24     60             False        1.18807                       0.663812   \n",
       "25     60             False       0.221225                       0.654133   \n",
       "26     60             False        0.21728                       0.654505   \n",
       "27     60             False        1.32622                       0.644453   \n",
       "28     60             False       0.217582                       0.655249   \n",
       "29     60             False       0.221153                       0.661579   \n",
       "30     60             False       0.231233                        0.65041   \n",
       "31     60             False        1.17304                       0.658972   \n",
       "32     60             False        1.16172                       0.656366   \n",
       "33     60             False       0.227786                       0.651526   \n",
       "34     60             False        1.18782                       0.664557   \n",
       "35     60             False        1.15275                       0.665302   \n",
       "36     60             False       0.213148                       0.650037   \n",
       "37     60             False          1.181                        0.67796   \n",
       "38     60             False        1.16788                       0.675354   \n",
       "39     60             False       0.210654                       0.663068   \n",
       "40     60             False        1.20454                       0.662323   \n",
       "41     60             False       0.248055                       0.641847   \n",
       "42     60             False       0.218664                       0.655622   \n",
       "43     60             False       0.239254                       0.645197   \n",
       "44     60             False        1.16542                       0.657111   \n",
       "45     60             False       0.230626                       0.647431   \n",
       "46     60             False       0.212857                       0.654133   \n",
       "47     60             False        1.15728                       0.664929   \n",
       "\n",
       "   test_val_loss_loss test_val_loss_categorical_accuracy  \n",
       "0            0.212126                           0.665302  \n",
       "1              1.1555                           0.661206  \n",
       "2            0.218776                           0.654133  \n",
       "3             1.21874                           0.652271  \n",
       "4            0.228509                           0.649293  \n",
       "5            0.211575                           0.656366  \n",
       "6             1.22251                           0.650782  \n",
       "7             0.24638                           0.639613  \n",
       "8            0.212747                           0.661206  \n",
       "9             1.26313                           0.654133  \n",
       "10           0.239131                           0.650782  \n",
       "11           0.218087                           0.652271  \n",
       "12            1.30223                           0.646314  \n",
       "13            1.17523                           0.654877  \n",
       "14            1.15993                           0.656739  \n",
       "15            1.13296                           0.667908  \n",
       "16            1.31771                           0.641474  \n",
       "17             1.1881                           0.659345  \n",
       "18            1.20371                           0.656366  \n",
       "19            1.20485                           0.652271  \n",
       "20            1.15033                           0.658972  \n",
       "21           0.210386                           0.658228  \n",
       "22           0.218716                           0.654505  \n",
       "23           0.209289                           0.662323  \n",
       "24            1.15028                           0.659717  \n",
       "25           0.208333                           0.658972  \n",
       "26           0.211745                           0.657483  \n",
       "27            1.32622                           0.644453  \n",
       "28           0.212273                           0.660834  \n",
       "29           0.211517                           0.653388  \n",
       "30           0.231233                            0.65041  \n",
       "31            1.17304                           0.658972  \n",
       "32            1.16006                           0.654505  \n",
       "33           0.227786                           0.651526  \n",
       "34            1.14598                           0.663068  \n",
       "35             1.1604                           0.661579  \n",
       "36           0.212067                           0.655249  \n",
       "37            1.12957                           0.670514  \n",
       "38            1.13248                           0.670141  \n",
       "39           0.205984                           0.655994  \n",
       "40            1.15853                           0.656739  \n",
       "41           0.248894                           0.644453  \n",
       "42           0.210448                             0.6586  \n",
       "43           0.239271                           0.644453  \n",
       "44            1.17307                           0.657483  \n",
       "45           0.230025                           0.648176  \n",
       "46           0.212857                           0.654133  \n",
       "47            1.15651                           0.665674  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", 100, \"display.max_columns\", 100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch</th>\n",
       "      <th>val_loss_epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>training_time</th>\n",
       "      <th>folder_name_prefix</th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lstm_layers</th>\n",
       "      <th>single_loss_function</th>\n",
       "      <th>multi_loss_function</th>\n",
       "      <th>optimiser</th>\n",
       "      <th>epochs</th>\n",
       "      <th>last_layer_inputs</th>\n",
       "      <th>test_loss_loss</th>\n",
       "      <th>test_loss_categorical_accuracy</th>\n",
       "      <th>test_val_loss_loss</th>\n",
       "      <th>test_val_loss_categorical_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.680145</td>\n",
       "      <td>0.676963</td>\n",
       "      <td>0.186522</td>\n",
       "      <td>0.202412</td>\n",
       "      <td>1655.73</td>\n",
       "      <td>babies</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.665302</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.665302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>0.82039</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.548099</td>\n",
       "      <td>1.11664</td>\n",
       "      <td>8219.02</td>\n",
       "      <td>locomotive</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2495</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>1.1555</td>\n",
       "      <td>0.661206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.660602</td>\n",
       "      <td>0.664682</td>\n",
       "      <td>0.200079</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>2717.54</td>\n",
       "      <td>blasts</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218776</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.218776</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.648178</td>\n",
       "      <td>0.66431</td>\n",
       "      <td>1.24743</td>\n",
       "      <td>1.1673</td>\n",
       "      <td>673.535</td>\n",
       "      <td>occasions</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.22061</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.21874</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>0.639663</td>\n",
       "      <td>0.658355</td>\n",
       "      <td>0.236961</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>728.228</td>\n",
       "      <td>boosts</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.22901</td>\n",
       "      <td>0.645197</td>\n",
       "      <td>0.228509</td>\n",
       "      <td>0.649293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.813643</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.0785895</td>\n",
       "      <td>0.204033</td>\n",
       "      <td>8140.34</td>\n",
       "      <td>stencils</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>0.648548</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.656366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.645526</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>1.25189</td>\n",
       "      <td>1.17244</td>\n",
       "      <td>700.752</td>\n",
       "      <td>manufacturers</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.22251</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.22251</td>\n",
       "      <td>0.650782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.61663</td>\n",
       "      <td>0.653517</td>\n",
       "      <td>0.260641</td>\n",
       "      <td>0.234228</td>\n",
       "      <td>1097.59</td>\n",
       "      <td>exercises</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.245478</td>\n",
       "      <td>0.637007</td>\n",
       "      <td>0.24638</td>\n",
       "      <td>0.639613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.678517</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.188837</td>\n",
       "      <td>0.202743</td>\n",
       "      <td>1699.03</td>\n",
       "      <td>definition</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212569</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.212747</td>\n",
       "      <td>0.661206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.641059</td>\n",
       "      <td>0.660588</td>\n",
       "      <td>1.29332</td>\n",
       "      <td>1.22162</td>\n",
       "      <td>1065.35</td>\n",
       "      <td>courtesy</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.26739</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>1.26313</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.628775</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>0.22813</td>\n",
       "      <td>1118.41</td>\n",
       "      <td>neutrons</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.650782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>0.679819</td>\n",
       "      <td>0.663937</td>\n",
       "      <td>0.180696</td>\n",
       "      <td>0.20642</td>\n",
       "      <td>2540.7</td>\n",
       "      <td>gold</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216906</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>0.218087</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.637383</td>\n",
       "      <td>0.655378</td>\n",
       "      <td>1.32786</td>\n",
       "      <td>1.2508</td>\n",
       "      <td>1064.19</td>\n",
       "      <td>objectives</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.30223</td>\n",
       "      <td>0.646314</td>\n",
       "      <td>1.30223</td>\n",
       "      <td>0.646314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.676004</td>\n",
       "      <td>0.66431</td>\n",
       "      <td>1.07857</td>\n",
       "      <td>1.12236</td>\n",
       "      <td>2595.09</td>\n",
       "      <td>cleanser</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17487</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.17523</td>\n",
       "      <td>0.654877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.831092</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>1.11164</td>\n",
       "      <td>7981.57</td>\n",
       "      <td>dangers</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.29186</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>1.15993</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>0.767298</td>\n",
       "      <td>0.688128</td>\n",
       "      <td>0.70721</td>\n",
       "      <td>1.09425</td>\n",
       "      <td>5225.05</td>\n",
       "      <td>respects</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15288</td>\n",
       "      <td>0.684289</td>\n",
       "      <td>1.13296</td>\n",
       "      <td>0.667908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.624261</td>\n",
       "      <td>0.654261</td>\n",
       "      <td>1.4138</td>\n",
       "      <td>1.26612</td>\n",
       "      <td>1053.15</td>\n",
       "      <td>thermals</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.31771</td>\n",
       "      <td>0.641474</td>\n",
       "      <td>1.31771</td>\n",
       "      <td>0.641474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>1.01041</td>\n",
       "      <td>1.13152</td>\n",
       "      <td>2551.2</td>\n",
       "      <td>overcoats</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17482</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>1.1881</td>\n",
       "      <td>0.659345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>0.655809</td>\n",
       "      <td>0.662449</td>\n",
       "      <td>1.19579</td>\n",
       "      <td>1.14602</td>\n",
       "      <td>698.305</td>\n",
       "      <td>milligram</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.19956</td>\n",
       "      <td>0.656739</td>\n",
       "      <td>1.20371</td>\n",
       "      <td>0.656366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.657671</td>\n",
       "      <td>0.661332</td>\n",
       "      <td>1.18994</td>\n",
       "      <td>1.15157</td>\n",
       "      <td>689.051</td>\n",
       "      <td>extenuations</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.20485</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>1.20485</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.702341</td>\n",
       "      <td>0.684034</td>\n",
       "      <td>0.96462</td>\n",
       "      <td>1.09052</td>\n",
       "      <td>1647.12</td>\n",
       "      <td>beginners</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15033</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>1.15033</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0.687218</td>\n",
       "      <td>0.673986</td>\n",
       "      <td>0.173029</td>\n",
       "      <td>0.200768</td>\n",
       "      <td>1652.37</td>\n",
       "      <td>trusts</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212168</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.210386</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.664325</td>\n",
       "      <td>0.66952</td>\n",
       "      <td>0.19427</td>\n",
       "      <td>0.203925</td>\n",
       "      <td>2593.95</td>\n",
       "      <td>influence</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.219316</td>\n",
       "      <td>0.654877</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>0.654505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>0.766414</td>\n",
       "      <td>0.681057</td>\n",
       "      <td>0.10742</td>\n",
       "      <td>0.196906</td>\n",
       "      <td>8764.39</td>\n",
       "      <td>hitches</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218377</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>0.209289</td>\n",
       "      <td>0.662323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777628</td>\n",
       "      <td>0.682173</td>\n",
       "      <td>0.676739</td>\n",
       "      <td>1.08384</td>\n",
       "      <td>8226.69</td>\n",
       "      <td>modem</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.18807</td>\n",
       "      <td>0.663812</td>\n",
       "      <td>1.15028</td>\n",
       "      <td>0.659717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.802615</td>\n",
       "      <td>0.66952</td>\n",
       "      <td>0.0835701</td>\n",
       "      <td>0.201177</td>\n",
       "      <td>5495.6</td>\n",
       "      <td>guilt</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.221225</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>0.762831</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.108168</td>\n",
       "      <td>0.200589</td>\n",
       "      <td>8184.2</td>\n",
       "      <td>door</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.21728</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.657483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.619329</td>\n",
       "      <td>0.655006</td>\n",
       "      <td>1.42453</td>\n",
       "      <td>1.28034</td>\n",
       "      <td>1070.94</td>\n",
       "      <td>submarine</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.32622</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>1.32622</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.754595</td>\n",
       "      <td>0.677707</td>\n",
       "      <td>0.114805</td>\n",
       "      <td>0.202691</td>\n",
       "      <td>5178.62</td>\n",
       "      <td>quality</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.217582</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.212273</td>\n",
       "      <td>0.660834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>0.802196</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.0850274</td>\n",
       "      <td>0.203961</td>\n",
       "      <td>8655.81</td>\n",
       "      <td>workman</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.221153</td>\n",
       "      <td>0.661579</td>\n",
       "      <td>0.211517</td>\n",
       "      <td>0.653388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.640826</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.238675</td>\n",
       "      <td>0.219339</td>\n",
       "      <td>698.085</td>\n",
       "      <td>stars</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.65041</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.65041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>1.00917</td>\n",
       "      <td>1.12038</td>\n",
       "      <td>2515.74</td>\n",
       "      <td>conjunctions</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17304</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>1.17304</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>0.696059</td>\n",
       "      <td>0.675102</td>\n",
       "      <td>0.984896</td>\n",
       "      <td>1.10634</td>\n",
       "      <td>1670.66</td>\n",
       "      <td>sparks</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16172</td>\n",
       "      <td>0.656366</td>\n",
       "      <td>1.16006</td>\n",
       "      <td>0.654505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.650179</td>\n",
       "      <td>0.660216</td>\n",
       "      <td>0.226623</td>\n",
       "      <td>0.21688</td>\n",
       "      <td>731.296</td>\n",
       "      <td>update</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.651526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.776651</td>\n",
       "      <td>0.668403</td>\n",
       "      <td>0.681971</td>\n",
       "      <td>1.1056</td>\n",
       "      <td>7997.1</td>\n",
       "      <td>discontinuance</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.18782</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>1.14598</td>\n",
       "      <td>0.663068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>0.685869</td>\n",
       "      <td>0.682173</td>\n",
       "      <td>1.03609</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>1639.1</td>\n",
       "      <td>metrics</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15275</td>\n",
       "      <td>0.665302</td>\n",
       "      <td>1.1604</td>\n",
       "      <td>0.661579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>0.685589</td>\n",
       "      <td>0.671381</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>0.205003</td>\n",
       "      <td>2684.12</td>\n",
       "      <td>stop</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.213148</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>0.212067</td>\n",
       "      <td>0.655249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.798427</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.618982</td>\n",
       "      <td>1.08209</td>\n",
       "      <td>5071.45</td>\n",
       "      <td>allegations</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.67796</td>\n",
       "      <td>1.12957</td>\n",
       "      <td>0.670514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.784887</td>\n",
       "      <td>0.687756</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>1.07315</td>\n",
       "      <td>5123.47</td>\n",
       "      <td>pits</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16788</td>\n",
       "      <td>0.675354</td>\n",
       "      <td>1.13248</td>\n",
       "      <td>0.670141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>0.764692</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.109621</td>\n",
       "      <td>0.198006</td>\n",
       "      <td>5485.84</td>\n",
       "      <td>ropes</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.210654</td>\n",
       "      <td>0.663068</td>\n",
       "      <td>0.205984</td>\n",
       "      <td>0.655994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.793728</td>\n",
       "      <td>0.681801</td>\n",
       "      <td>0.62204</td>\n",
       "      <td>1.10993</td>\n",
       "      <td>5243.47</td>\n",
       "      <td>currencies</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.20454</td>\n",
       "      <td>0.662323</td>\n",
       "      <td>1.15853</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.617049</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.261387</td>\n",
       "      <td>0.234265</td>\n",
       "      <td>1074.27</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.248055</td>\n",
       "      <td>0.641847</td>\n",
       "      <td>0.248894</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.0939058</td>\n",
       "      <td>0.20267</td>\n",
       "      <td>5191.32</td>\n",
       "      <td>courtesy</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>0.6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.631055</td>\n",
       "      <td>0.65575</td>\n",
       "      <td>0.242749</td>\n",
       "      <td>0.22886</td>\n",
       "      <td>1064.7</td>\n",
       "      <td>morning</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239254</td>\n",
       "      <td>0.645197</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0.677633</td>\n",
       "      <td>0.672869</td>\n",
       "      <td>1.07388</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>2537.64</td>\n",
       "      <td>backups</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16542</td>\n",
       "      <td>0.657111</td>\n",
       "      <td>1.17307</td>\n",
       "      <td>0.657483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.643432</td>\n",
       "      <td>0.66096</td>\n",
       "      <td>0.228271</td>\n",
       "      <td>0.215703</td>\n",
       "      <td>700.107</td>\n",
       "      <td>thirteen</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.230626</td>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.230025</td>\n",
       "      <td>0.648176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.690382</td>\n",
       "      <td>0.674358</td>\n",
       "      <td>0.174754</td>\n",
       "      <td>0.19998</td>\n",
       "      <td>1767.04</td>\n",
       "      <td>color</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.679196</td>\n",
       "      <td>1.04545</td>\n",
       "      <td>1.10519</td>\n",
       "      <td>1672.15</td>\n",
       "      <td>wine</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15728</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>1.15651</td>\n",
       "      <td>0.665674</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_epoch val_loss_epoch categorical_accuracy val_categorical_accuracy  \\\n",
       "0          60             60             0.680145                 0.676963   \n",
       "1          60             29              0.82039                 0.670636   \n",
       "2          60             60             0.660602                 0.664682   \n",
       "3          59             60             0.648178                  0.66431   \n",
       "4          58             60             0.639663                 0.658355   \n",
       "5          60             37             0.813643                 0.663193   \n",
       "6          60             60             0.645526                 0.656494   \n",
       "7          60             59              0.61663                 0.653517   \n",
       "8          60             57             0.678517                 0.675475   \n",
       "9          59             60             0.641059                 0.660588   \n",
       "10         59             59             0.628775                 0.656494   \n",
       "11         60             56             0.679819                 0.663937   \n",
       "12         60             60             0.637383                 0.655378   \n",
       "13         60             57             0.676004                  0.66431   \n",
       "14         60             30             0.831092                 0.675475   \n",
       "15         60             42             0.767298                 0.688128   \n",
       "16         60             60             0.624261                 0.654261   \n",
       "17         59             49             0.689219                 0.670636   \n",
       "18         58             60             0.655809                 0.662449   \n",
       "19         60             60             0.657671                 0.661332   \n",
       "20         59             59             0.702341                 0.684034   \n",
       "21         60             54             0.687218                 0.673986   \n",
       "22         60             59             0.664325                  0.66952   \n",
       "23         60             45             0.766414                 0.681057   \n",
       "24         60             36             0.777628                 0.682173   \n",
       "25         60             37             0.802615                  0.66952   \n",
       "26         60             49             0.762831                 0.668031   \n",
       "27         60             60             0.619329                 0.655006   \n",
       "28         60             34             0.754595                 0.677707   \n",
       "29         57             41             0.802196                 0.659472   \n",
       "30         59             59             0.640826                 0.659472   \n",
       "31         60             60             0.689591                 0.676591   \n",
       "32         60             53             0.696059                 0.675102   \n",
       "33         60             60             0.650179                 0.660216   \n",
       "34         60             40             0.776651                 0.668403   \n",
       "35         59             55             0.685869                 0.682173   \n",
       "36         60             58             0.685589                 0.671381   \n",
       "37         60             34             0.798427                  0.69185   \n",
       "38         60             36             0.784887                 0.687756   \n",
       "39         60             41             0.764692                 0.676591   \n",
       "40         60             34             0.793728                 0.681801   \n",
       "41         60             59             0.617049                 0.651656   \n",
       "42         60             33             0.784235                 0.665798   \n",
       "43         60             59             0.631055                  0.65575   \n",
       "44         60             54             0.677633                 0.672869   \n",
       "45         59             60             0.643432                  0.66096   \n",
       "46         60             60             0.690382                 0.674358   \n",
       "47         59             57             0.681913                 0.679196   \n",
       "\n",
       "         loss  val_loss training_time folder_name_prefix lstm_units dropout  \\\n",
       "0    0.186522  0.202412       1655.73             babies        128     0.3   \n",
       "1    0.548099   1.11664       8219.02         locomotive        256     0.2   \n",
       "2    0.200079  0.207182       2717.54             blasts        128     0.3   \n",
       "3     1.24743    1.1673       673.535          occasions         64     0.3   \n",
       "4    0.236961    0.2174       728.228             boosts         64     0.3   \n",
       "5   0.0785895  0.204033       8140.34           stencils        256     0.2   \n",
       "6     1.25189   1.17244       700.752      manufacturers         64     0.3   \n",
       "7    0.260641  0.234228       1097.59          exercises         64     0.3   \n",
       "8    0.188837  0.202743       1699.03         definition        128     0.3   \n",
       "9     1.29332   1.22162       1065.35           courtesy         64     0.2   \n",
       "10   0.244774   0.22813       1118.41           neutrons         64     0.2   \n",
       "11   0.180696   0.20642        2540.7               gold        128     0.2   \n",
       "12    1.32786    1.2508       1064.19         objectives         64     0.2   \n",
       "13    1.07857   1.12236       2595.09           cleanser        128     0.3   \n",
       "14   0.511027   1.11164       7981.57            dangers        256     0.2   \n",
       "15    0.70721   1.09425       5225.05           respects        256     0.3   \n",
       "16     1.4138   1.26612       1053.15           thermals         64     0.3   \n",
       "17    1.01041   1.13152        2551.2          overcoats        128     0.2   \n",
       "18    1.19579   1.14602       698.305          milligram         64     0.2   \n",
       "19    1.18994   1.15157       689.051       extenuations         64     0.2   \n",
       "20    0.96462   1.09052       1647.12          beginners        128     0.2   \n",
       "21   0.173029  0.200768       1652.37             trusts        128     0.2   \n",
       "22    0.19427  0.203925       2593.95          influence        128     0.3   \n",
       "23    0.10742  0.196906       8764.39            hitches        256     0.3   \n",
       "24   0.676739   1.08384       8226.69              modem        256     0.3   \n",
       "25  0.0835701  0.201177        5495.6              guilt        256     0.2   \n",
       "26   0.108168  0.200589        8184.2               door        256     0.3   \n",
       "27    1.42453   1.28034       1070.94          submarine         64     0.3   \n",
       "28   0.114805  0.202691       5178.62            quality        256     0.3   \n",
       "29  0.0850274  0.203961       8655.81            workman        256     0.2   \n",
       "30   0.238675  0.219339       698.085              stars         64     0.3   \n",
       "31    1.00917   1.12038       2515.74       conjunctions        128     0.2   \n",
       "32   0.984896   1.10634       1670.66             sparks        128     0.2   \n",
       "33   0.226623   0.21688       731.296             update         64     0.2   \n",
       "34   0.681971    1.1056        7997.1     discontinuance        256     0.3   \n",
       "35    1.03609    1.0986        1639.1            metrics        128     0.3   \n",
       "36   0.176514  0.205003       2684.12               stop        128     0.2   \n",
       "37   0.618982   1.08209       5071.45        allegations        256     0.2   \n",
       "38   0.657706   1.07315       5123.47               pits        256     0.3   \n",
       "39   0.109621  0.198006       5485.84              ropes        256     0.3   \n",
       "40    0.62204   1.10993       5243.47         currencies        256     0.2   \n",
       "41   0.261387  0.234265       1074.27        acquisition         64     0.3   \n",
       "42  0.0939058   0.20267       5191.32           courtesy        256     0.2   \n",
       "43   0.242749   0.22886        1064.7            morning         64     0.2   \n",
       "44    1.07388    1.1225       2537.64            backups        128     0.3   \n",
       "45   0.228271  0.215703       700.107           thirteen         64     0.2   \n",
       "46   0.174754   0.19998       1767.04              color        128     0.2   \n",
       "47    1.04545   1.10519       1672.15               wine        128     0.3   \n",
       "\n",
       "   lstm_layers      single_loss_function  multi_loss_function optimiser  \\\n",
       "0            2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "1            3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "2            3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "3            2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "4            2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "5            3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "6            2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "7            3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "8            2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "9            3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "10           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "11           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "12           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "13           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "14           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "15           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "16           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "17           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "18           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "19           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "20           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "21           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "22           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "23           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "24           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "25           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "26           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "27           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "28           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "29           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "30           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "31           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "32           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "33           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "34           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "35           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "36           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "37           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "38           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "39           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "40           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "41           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "42           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "43           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "44           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "45           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "46           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "47           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "\n",
       "   epochs last_layer_inputs test_loss_loss test_loss_categorical_accuracy  \\\n",
       "0      60             False       0.212126                       0.665302   \n",
       "1      60             False         1.2495                         0.6586   \n",
       "2      60             False       0.218776                       0.654133   \n",
       "3      60             False        1.22061                       0.650782   \n",
       "4      60             False        0.22901                       0.645197   \n",
       "5      60             False       0.227899                       0.648548   \n",
       "6      60             False        1.22251                       0.650782   \n",
       "7      60             False       0.245478                       0.637007   \n",
       "8      60             False       0.212569                       0.658228   \n",
       "9      60             False        1.26739                       0.650037   \n",
       "10     60             False       0.239131                       0.650782   \n",
       "11     60             False       0.216906                       0.652271   \n",
       "12     60             False        1.30223                       0.646314   \n",
       "13     60             False        1.17487                       0.650782   \n",
       "14     60             False        1.29186                       0.650037   \n",
       "15     60             False        1.15288                       0.684289   \n",
       "16     60             False        1.31771                       0.641474   \n",
       "17     60             False        1.17482                       0.664557   \n",
       "18     60             False        1.19956                       0.656739   \n",
       "19     60             False        1.20485                       0.652271   \n",
       "20     60             False        1.15033                       0.658972   \n",
       "21     60             False       0.212168                       0.655622   \n",
       "22     60             False       0.219316                       0.654877   \n",
       "23     60             False       0.218377                       0.658972   \n",
       "24     60             False        1.18807                       0.663812   \n",
       "25     60             False       0.221225                       0.654133   \n",
       "26     60             False        0.21728                       0.654505   \n",
       "27     60             False        1.32622                       0.644453   \n",
       "28     60             False       0.217582                       0.655249   \n",
       "29     60             False       0.221153                       0.661579   \n",
       "30     60             False       0.231233                        0.65041   \n",
       "31     60             False        1.17304                       0.658972   \n",
       "32     60             False        1.16172                       0.656366   \n",
       "33     60             False       0.227786                       0.651526   \n",
       "34     60             False        1.18782                       0.664557   \n",
       "35     60             False        1.15275                       0.665302   \n",
       "36     60             False       0.213148                       0.650037   \n",
       "37     60             False          1.181                        0.67796   \n",
       "38     60             False        1.16788                       0.675354   \n",
       "39     60             False       0.210654                       0.663068   \n",
       "40     60             False        1.20454                       0.662323   \n",
       "41     60             False       0.248055                       0.641847   \n",
       "42     60             False       0.218664                       0.655622   \n",
       "43     60             False       0.239254                       0.645197   \n",
       "44     60             False        1.16542                       0.657111   \n",
       "45     60             False       0.230626                       0.647431   \n",
       "46     60             False       0.212857                       0.654133   \n",
       "47     60             False        1.15728                       0.664929   \n",
       "\n",
       "   test_val_loss_loss test_val_loss_categorical_accuracy  \n",
       "0            0.212126                           0.665302  \n",
       "1              1.1555                           0.661206  \n",
       "2            0.218776                           0.654133  \n",
       "3             1.21874                           0.652271  \n",
       "4            0.228509                           0.649293  \n",
       "5            0.211575                           0.656366  \n",
       "6             1.22251                           0.650782  \n",
       "7             0.24638                           0.639613  \n",
       "8            0.212747                           0.661206  \n",
       "9             1.26313                           0.654133  \n",
       "10           0.239131                           0.650782  \n",
       "11           0.218087                           0.652271  \n",
       "12            1.30223                           0.646314  \n",
       "13            1.17523                           0.654877  \n",
       "14            1.15993                           0.656739  \n",
       "15            1.13296                           0.667908  \n",
       "16            1.31771                           0.641474  \n",
       "17             1.1881                           0.659345  \n",
       "18            1.20371                           0.656366  \n",
       "19            1.20485                           0.652271  \n",
       "20            1.15033                           0.658972  \n",
       "21           0.210386                           0.658228  \n",
       "22           0.218716                           0.654505  \n",
       "23           0.209289                           0.662323  \n",
       "24            1.15028                           0.659717  \n",
       "25           0.208333                           0.658972  \n",
       "26           0.211745                           0.657483  \n",
       "27            1.32622                           0.644453  \n",
       "28           0.212273                           0.660834  \n",
       "29           0.211517                           0.653388  \n",
       "30           0.231233                            0.65041  \n",
       "31            1.17304                           0.658972  \n",
       "32            1.16006                           0.654505  \n",
       "33           0.227786                           0.651526  \n",
       "34            1.14598                           0.663068  \n",
       "35             1.1604                           0.661579  \n",
       "36           0.212067                           0.655249  \n",
       "37            1.12957                           0.670514  \n",
       "38            1.13248                           0.670141  \n",
       "39           0.205984                           0.655994  \n",
       "40            1.15853                           0.656739  \n",
       "41           0.248894                           0.644453  \n",
       "42           0.210448                             0.6586  \n",
       "43           0.239271                           0.644453  \n",
       "44            1.17307                           0.657483  \n",
       "45           0.230025                           0.648176  \n",
       "46           0.212857                           0.654133  \n",
       "47            1.15651                           0.665674  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss_epoch</th>\n",
       "      <th>val_loss_epoch</th>\n",
       "      <th>categorical_accuracy</th>\n",
       "      <th>val_categorical_accuracy</th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>training_time</th>\n",
       "      <th>folder_name_prefix</th>\n",
       "      <th>lstm_units</th>\n",
       "      <th>dropout</th>\n",
       "      <th>lstm_layers</th>\n",
       "      <th>single_loss_function</th>\n",
       "      <th>multi_loss_function</th>\n",
       "      <th>optimiser</th>\n",
       "      <th>epochs</th>\n",
       "      <th>last_layer_inputs</th>\n",
       "      <th>test_loss_loss</th>\n",
       "      <th>test_loss_categorical_accuracy</th>\n",
       "      <th>test_val_loss_loss</th>\n",
       "      <th>test_val_loss_categorical_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.798427</td>\n",
       "      <td>0.69185</td>\n",
       "      <td>0.618982</td>\n",
       "      <td>1.08209</td>\n",
       "      <td>5071.45</td>\n",
       "      <td>allegations</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.181</td>\n",
       "      <td>0.67796</td>\n",
       "      <td>1.12957</td>\n",
       "      <td>0.670514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.784887</td>\n",
       "      <td>0.687756</td>\n",
       "      <td>0.657706</td>\n",
       "      <td>1.07315</td>\n",
       "      <td>5123.47</td>\n",
       "      <td>pits</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16788</td>\n",
       "      <td>0.675354</td>\n",
       "      <td>1.13248</td>\n",
       "      <td>0.670141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>60</td>\n",
       "      <td>42</td>\n",
       "      <td>0.767298</td>\n",
       "      <td>0.688128</td>\n",
       "      <td>0.70721</td>\n",
       "      <td>1.09425</td>\n",
       "      <td>5225.05</td>\n",
       "      <td>respects</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15288</td>\n",
       "      <td>0.684289</td>\n",
       "      <td>1.13296</td>\n",
       "      <td>0.667908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>59</td>\n",
       "      <td>57</td>\n",
       "      <td>0.681913</td>\n",
       "      <td>0.679196</td>\n",
       "      <td>1.04545</td>\n",
       "      <td>1.10519</td>\n",
       "      <td>1672.15</td>\n",
       "      <td>wine</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15728</td>\n",
       "      <td>0.664929</td>\n",
       "      <td>1.15651</td>\n",
       "      <td>0.665674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.680145</td>\n",
       "      <td>0.676963</td>\n",
       "      <td>0.186522</td>\n",
       "      <td>0.202412</td>\n",
       "      <td>1655.73</td>\n",
       "      <td>babies</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.665302</td>\n",
       "      <td>0.212126</td>\n",
       "      <td>0.665302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>60</td>\n",
       "      <td>40</td>\n",
       "      <td>0.776651</td>\n",
       "      <td>0.668403</td>\n",
       "      <td>0.681971</td>\n",
       "      <td>1.1056</td>\n",
       "      <td>7997.1</td>\n",
       "      <td>discontinuance</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.18782</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>1.14598</td>\n",
       "      <td>0.663068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>0.766414</td>\n",
       "      <td>0.681057</td>\n",
       "      <td>0.10742</td>\n",
       "      <td>0.196906</td>\n",
       "      <td>8764.39</td>\n",
       "      <td>hitches</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218377</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>0.209289</td>\n",
       "      <td>0.662323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>59</td>\n",
       "      <td>55</td>\n",
       "      <td>0.685869</td>\n",
       "      <td>0.682173</td>\n",
       "      <td>1.03609</td>\n",
       "      <td>1.0986</td>\n",
       "      <td>1639.1</td>\n",
       "      <td>metrics</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15275</td>\n",
       "      <td>0.665302</td>\n",
       "      <td>1.1604</td>\n",
       "      <td>0.661579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.678517</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.188837</td>\n",
       "      <td>0.202743</td>\n",
       "      <td>1699.03</td>\n",
       "      <td>definition</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212569</td>\n",
       "      <td>0.658228</td>\n",
       "      <td>0.212747</td>\n",
       "      <td>0.661206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>60</td>\n",
       "      <td>29</td>\n",
       "      <td>0.82039</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>0.548099</td>\n",
       "      <td>1.11664</td>\n",
       "      <td>8219.02</td>\n",
       "      <td>locomotive</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.2495</td>\n",
       "      <td>0.6586</td>\n",
       "      <td>1.1555</td>\n",
       "      <td>0.661206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.754595</td>\n",
       "      <td>0.677707</td>\n",
       "      <td>0.114805</td>\n",
       "      <td>0.202691</td>\n",
       "      <td>5178.62</td>\n",
       "      <td>quality</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.217582</td>\n",
       "      <td>0.655249</td>\n",
       "      <td>0.212273</td>\n",
       "      <td>0.660834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>60</td>\n",
       "      <td>36</td>\n",
       "      <td>0.777628</td>\n",
       "      <td>0.682173</td>\n",
       "      <td>0.676739</td>\n",
       "      <td>1.08384</td>\n",
       "      <td>8226.69</td>\n",
       "      <td>modem</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.18807</td>\n",
       "      <td>0.663812</td>\n",
       "      <td>1.15028</td>\n",
       "      <td>0.659717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>59</td>\n",
       "      <td>49</td>\n",
       "      <td>0.689219</td>\n",
       "      <td>0.670636</td>\n",
       "      <td>1.01041</td>\n",
       "      <td>1.13152</td>\n",
       "      <td>2551.2</td>\n",
       "      <td>overcoats</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17482</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>1.1881</td>\n",
       "      <td>0.659345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.702341</td>\n",
       "      <td>0.684034</td>\n",
       "      <td>0.96462</td>\n",
       "      <td>1.09052</td>\n",
       "      <td>1647.12</td>\n",
       "      <td>beginners</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.15033</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>1.15033</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.689591</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>1.00917</td>\n",
       "      <td>1.12038</td>\n",
       "      <td>2515.74</td>\n",
       "      <td>conjunctions</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17304</td>\n",
       "      <td>0.658972</td>\n",
       "      <td>1.17304</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.802615</td>\n",
       "      <td>0.66952</td>\n",
       "      <td>0.0835701</td>\n",
       "      <td>0.201177</td>\n",
       "      <td>5495.6</td>\n",
       "      <td>guilt</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.221225</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.658972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>60</td>\n",
       "      <td>33</td>\n",
       "      <td>0.784235</td>\n",
       "      <td>0.665798</td>\n",
       "      <td>0.0939058</td>\n",
       "      <td>0.20267</td>\n",
       "      <td>5191.32</td>\n",
       "      <td>courtesy</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218664</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.210448</td>\n",
       "      <td>0.6586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0.687218</td>\n",
       "      <td>0.673986</td>\n",
       "      <td>0.173029</td>\n",
       "      <td>0.200768</td>\n",
       "      <td>1652.37</td>\n",
       "      <td>trusts</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212168</td>\n",
       "      <td>0.655622</td>\n",
       "      <td>0.210386</td>\n",
       "      <td>0.658228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>0.677633</td>\n",
       "      <td>0.672869</td>\n",
       "      <td>1.07388</td>\n",
       "      <td>1.1225</td>\n",
       "      <td>2537.64</td>\n",
       "      <td>backups</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16542</td>\n",
       "      <td>0.657111</td>\n",
       "      <td>1.17307</td>\n",
       "      <td>0.657483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>60</td>\n",
       "      <td>49</td>\n",
       "      <td>0.762831</td>\n",
       "      <td>0.668031</td>\n",
       "      <td>0.108168</td>\n",
       "      <td>0.200589</td>\n",
       "      <td>8184.2</td>\n",
       "      <td>door</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.21728</td>\n",
       "      <td>0.654505</td>\n",
       "      <td>0.211745</td>\n",
       "      <td>0.657483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>60</td>\n",
       "      <td>30</td>\n",
       "      <td>0.831092</td>\n",
       "      <td>0.675475</td>\n",
       "      <td>0.511027</td>\n",
       "      <td>1.11164</td>\n",
       "      <td>7981.57</td>\n",
       "      <td>dangers</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.29186</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>1.15993</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>0.793728</td>\n",
       "      <td>0.681801</td>\n",
       "      <td>0.62204</td>\n",
       "      <td>1.10993</td>\n",
       "      <td>5243.47</td>\n",
       "      <td>currencies</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.20454</td>\n",
       "      <td>0.662323</td>\n",
       "      <td>1.15853</td>\n",
       "      <td>0.656739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>37</td>\n",
       "      <td>0.813643</td>\n",
       "      <td>0.663193</td>\n",
       "      <td>0.0785895</td>\n",
       "      <td>0.204033</td>\n",
       "      <td>8140.34</td>\n",
       "      <td>stencils</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227899</td>\n",
       "      <td>0.648548</td>\n",
       "      <td>0.211575</td>\n",
       "      <td>0.656366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>0.655809</td>\n",
       "      <td>0.662449</td>\n",
       "      <td>1.19579</td>\n",
       "      <td>1.14602</td>\n",
       "      <td>698.305</td>\n",
       "      <td>milligram</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.19956</td>\n",
       "      <td>0.656739</td>\n",
       "      <td>1.20371</td>\n",
       "      <td>0.656366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>60</td>\n",
       "      <td>41</td>\n",
       "      <td>0.764692</td>\n",
       "      <td>0.676591</td>\n",
       "      <td>0.109621</td>\n",
       "      <td>0.198006</td>\n",
       "      <td>5485.84</td>\n",
       "      <td>ropes</td>\n",
       "      <td>256</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.210654</td>\n",
       "      <td>0.663068</td>\n",
       "      <td>0.205984</td>\n",
       "      <td>0.655994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>60</td>\n",
       "      <td>58</td>\n",
       "      <td>0.685589</td>\n",
       "      <td>0.671381</td>\n",
       "      <td>0.176514</td>\n",
       "      <td>0.205003</td>\n",
       "      <td>2684.12</td>\n",
       "      <td>stop</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.213148</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>0.212067</td>\n",
       "      <td>0.655249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>60</td>\n",
       "      <td>57</td>\n",
       "      <td>0.676004</td>\n",
       "      <td>0.66431</td>\n",
       "      <td>1.07857</td>\n",
       "      <td>1.12236</td>\n",
       "      <td>2595.09</td>\n",
       "      <td>cleanser</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.17487</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.17523</td>\n",
       "      <td>0.654877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.664325</td>\n",
       "      <td>0.66952</td>\n",
       "      <td>0.19427</td>\n",
       "      <td>0.203925</td>\n",
       "      <td>2593.95</td>\n",
       "      <td>influence</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.219316</td>\n",
       "      <td>0.654877</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>0.654505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>60</td>\n",
       "      <td>53</td>\n",
       "      <td>0.696059</td>\n",
       "      <td>0.675102</td>\n",
       "      <td>0.984896</td>\n",
       "      <td>1.10634</td>\n",
       "      <td>1670.66</td>\n",
       "      <td>sparks</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.16172</td>\n",
       "      <td>0.656366</td>\n",
       "      <td>1.16006</td>\n",
       "      <td>0.654505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.690382</td>\n",
       "      <td>0.674358</td>\n",
       "      <td>0.174754</td>\n",
       "      <td>0.19998</td>\n",
       "      <td>1767.04</td>\n",
       "      <td>color</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.212857</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.641059</td>\n",
       "      <td>0.660588</td>\n",
       "      <td>1.29332</td>\n",
       "      <td>1.22162</td>\n",
       "      <td>1065.35</td>\n",
       "      <td>courtesy</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.26739</td>\n",
       "      <td>0.650037</td>\n",
       "      <td>1.26313</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.660602</td>\n",
       "      <td>0.664682</td>\n",
       "      <td>0.200079</td>\n",
       "      <td>0.207182</td>\n",
       "      <td>2717.54</td>\n",
       "      <td>blasts</td>\n",
       "      <td>128</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.218776</td>\n",
       "      <td>0.654133</td>\n",
       "      <td>0.218776</td>\n",
       "      <td>0.654133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>57</td>\n",
       "      <td>41</td>\n",
       "      <td>0.802196</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.0850274</td>\n",
       "      <td>0.203961</td>\n",
       "      <td>8655.81</td>\n",
       "      <td>workman</td>\n",
       "      <td>256</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.221153</td>\n",
       "      <td>0.661579</td>\n",
       "      <td>0.211517</td>\n",
       "      <td>0.653388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.648178</td>\n",
       "      <td>0.66431</td>\n",
       "      <td>1.24743</td>\n",
       "      <td>1.1673</td>\n",
       "      <td>673.535</td>\n",
       "      <td>occasions</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.22061</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.21874</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.657671</td>\n",
       "      <td>0.661332</td>\n",
       "      <td>1.18994</td>\n",
       "      <td>1.15157</td>\n",
       "      <td>689.051</td>\n",
       "      <td>extenuations</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.20485</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>1.20485</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>60</td>\n",
       "      <td>56</td>\n",
       "      <td>0.679819</td>\n",
       "      <td>0.663937</td>\n",
       "      <td>0.180696</td>\n",
       "      <td>0.20642</td>\n",
       "      <td>2540.7</td>\n",
       "      <td>gold</td>\n",
       "      <td>128</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.216906</td>\n",
       "      <td>0.652271</td>\n",
       "      <td>0.218087</td>\n",
       "      <td>0.652271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.650179</td>\n",
       "      <td>0.660216</td>\n",
       "      <td>0.226623</td>\n",
       "      <td>0.21688</td>\n",
       "      <td>731.296</td>\n",
       "      <td>update</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.651526</td>\n",
       "      <td>0.227786</td>\n",
       "      <td>0.651526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.628775</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>0.244774</td>\n",
       "      <td>0.22813</td>\n",
       "      <td>1118.41</td>\n",
       "      <td>neutrons</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>0.239131</td>\n",
       "      <td>0.650782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.645526</td>\n",
       "      <td>0.656494</td>\n",
       "      <td>1.25189</td>\n",
       "      <td>1.17244</td>\n",
       "      <td>700.752</td>\n",
       "      <td>manufacturers</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.22251</td>\n",
       "      <td>0.650782</td>\n",
       "      <td>1.22251</td>\n",
       "      <td>0.650782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>59</td>\n",
       "      <td>59</td>\n",
       "      <td>0.640826</td>\n",
       "      <td>0.659472</td>\n",
       "      <td>0.238675</td>\n",
       "      <td>0.219339</td>\n",
       "      <td>698.085</td>\n",
       "      <td>stars</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.65041</td>\n",
       "      <td>0.231233</td>\n",
       "      <td>0.65041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>60</td>\n",
       "      <td>0.639663</td>\n",
       "      <td>0.658355</td>\n",
       "      <td>0.236961</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>728.228</td>\n",
       "      <td>boosts</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.22901</td>\n",
       "      <td>0.645197</td>\n",
       "      <td>0.228509</td>\n",
       "      <td>0.649293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>59</td>\n",
       "      <td>60</td>\n",
       "      <td>0.643432</td>\n",
       "      <td>0.66096</td>\n",
       "      <td>0.228271</td>\n",
       "      <td>0.215703</td>\n",
       "      <td>700.107</td>\n",
       "      <td>thirteen</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.230626</td>\n",
       "      <td>0.647431</td>\n",
       "      <td>0.230025</td>\n",
       "      <td>0.648176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.637383</td>\n",
       "      <td>0.655378</td>\n",
       "      <td>1.32786</td>\n",
       "      <td>1.2508</td>\n",
       "      <td>1064.19</td>\n",
       "      <td>objectives</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.30223</td>\n",
       "      <td>0.646314</td>\n",
       "      <td>1.30223</td>\n",
       "      <td>0.646314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.619329</td>\n",
       "      <td>0.655006</td>\n",
       "      <td>1.42453</td>\n",
       "      <td>1.28034</td>\n",
       "      <td>1070.94</td>\n",
       "      <td>submarine</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.32622</td>\n",
       "      <td>0.644453</td>\n",
       "      <td>1.32622</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.617049</td>\n",
       "      <td>0.651656</td>\n",
       "      <td>0.261387</td>\n",
       "      <td>0.234265</td>\n",
       "      <td>1074.27</td>\n",
       "      <td>acquisition</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.248055</td>\n",
       "      <td>0.641847</td>\n",
       "      <td>0.248894</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.631055</td>\n",
       "      <td>0.65575</td>\n",
       "      <td>0.242749</td>\n",
       "      <td>0.22886</td>\n",
       "      <td>1064.7</td>\n",
       "      <td>morning</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>rmsprop</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.239254</td>\n",
       "      <td>0.645197</td>\n",
       "      <td>0.239271</td>\n",
       "      <td>0.644453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0.624261</td>\n",
       "      <td>0.654261</td>\n",
       "      <td>1.4138</td>\n",
       "      <td>1.26612</td>\n",
       "      <td>1053.15</td>\n",
       "      <td>thermals</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_crossentropy</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>1.31771</td>\n",
       "      <td>0.641474</td>\n",
       "      <td>1.31771</td>\n",
       "      <td>0.641474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>60</td>\n",
       "      <td>59</td>\n",
       "      <td>0.61663</td>\n",
       "      <td>0.653517</td>\n",
       "      <td>0.260641</td>\n",
       "      <td>0.234228</td>\n",
       "      <td>1097.59</td>\n",
       "      <td>exercises</td>\n",
       "      <td>64</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3</td>\n",
       "      <td>categorical_focal_loss</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>adam</td>\n",
       "      <td>60</td>\n",
       "      <td>False</td>\n",
       "      <td>0.245478</td>\n",
       "      <td>0.637007</td>\n",
       "      <td>0.24638</td>\n",
       "      <td>0.639613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loss_epoch val_loss_epoch categorical_accuracy val_categorical_accuracy  \\\n",
       "37         60             34             0.798427                  0.69185   \n",
       "38         60             36             0.784887                 0.687756   \n",
       "15         60             42             0.767298                 0.688128   \n",
       "47         59             57             0.681913                 0.679196   \n",
       "0          60             60             0.680145                 0.676963   \n",
       "34         60             40             0.776651                 0.668403   \n",
       "23         60             45             0.766414                 0.681057   \n",
       "35         59             55             0.685869                 0.682173   \n",
       "8          60             57             0.678517                 0.675475   \n",
       "1          60             29              0.82039                 0.670636   \n",
       "28         60             34             0.754595                 0.677707   \n",
       "24         60             36             0.777628                 0.682173   \n",
       "17         59             49             0.689219                 0.670636   \n",
       "20         59             59             0.702341                 0.684034   \n",
       "31         60             60             0.689591                 0.676591   \n",
       "25         60             37             0.802615                  0.66952   \n",
       "42         60             33             0.784235                 0.665798   \n",
       "21         60             54             0.687218                 0.673986   \n",
       "44         60             54             0.677633                 0.672869   \n",
       "26         60             49             0.762831                 0.668031   \n",
       "14         60             30             0.831092                 0.675475   \n",
       "40         60             34             0.793728                 0.681801   \n",
       "5          60             37             0.813643                 0.663193   \n",
       "18         58             60             0.655809                 0.662449   \n",
       "39         60             41             0.764692                 0.676591   \n",
       "36         60             58             0.685589                 0.671381   \n",
       "13         60             57             0.676004                  0.66431   \n",
       "22         60             59             0.664325                  0.66952   \n",
       "32         60             53             0.696059                 0.675102   \n",
       "46         60             60             0.690382                 0.674358   \n",
       "9          59             60             0.641059                 0.660588   \n",
       "2          60             60             0.660602                 0.664682   \n",
       "29         57             41             0.802196                 0.659472   \n",
       "3          59             60             0.648178                  0.66431   \n",
       "19         60             60             0.657671                 0.661332   \n",
       "11         60             56             0.679819                 0.663937   \n",
       "33         60             60             0.650179                 0.660216   \n",
       "10         59             59             0.628775                 0.656494   \n",
       "6          60             60             0.645526                 0.656494   \n",
       "30         59             59             0.640826                 0.659472   \n",
       "4          58             60             0.639663                 0.658355   \n",
       "45         59             60             0.643432                  0.66096   \n",
       "12         60             60             0.637383                 0.655378   \n",
       "27         60             60             0.619329                 0.655006   \n",
       "41         60             59             0.617049                 0.651656   \n",
       "43         60             59             0.631055                  0.65575   \n",
       "16         60             60             0.624261                 0.654261   \n",
       "7          60             59              0.61663                 0.653517   \n",
       "\n",
       "         loss  val_loss training_time folder_name_prefix lstm_units dropout  \\\n",
       "37   0.618982   1.08209       5071.45        allegations        256     0.2   \n",
       "38   0.657706   1.07315       5123.47               pits        256     0.3   \n",
       "15    0.70721   1.09425       5225.05           respects        256     0.3   \n",
       "47    1.04545   1.10519       1672.15               wine        128     0.3   \n",
       "0    0.186522  0.202412       1655.73             babies        128     0.3   \n",
       "34   0.681971    1.1056        7997.1     discontinuance        256     0.3   \n",
       "23    0.10742  0.196906       8764.39            hitches        256     0.3   \n",
       "35    1.03609    1.0986        1639.1            metrics        128     0.3   \n",
       "8    0.188837  0.202743       1699.03         definition        128     0.3   \n",
       "1    0.548099   1.11664       8219.02         locomotive        256     0.2   \n",
       "28   0.114805  0.202691       5178.62            quality        256     0.3   \n",
       "24   0.676739   1.08384       8226.69              modem        256     0.3   \n",
       "17    1.01041   1.13152        2551.2          overcoats        128     0.2   \n",
       "20    0.96462   1.09052       1647.12          beginners        128     0.2   \n",
       "31    1.00917   1.12038       2515.74       conjunctions        128     0.2   \n",
       "25  0.0835701  0.201177        5495.6              guilt        256     0.2   \n",
       "42  0.0939058   0.20267       5191.32           courtesy        256     0.2   \n",
       "21   0.173029  0.200768       1652.37             trusts        128     0.2   \n",
       "44    1.07388    1.1225       2537.64            backups        128     0.3   \n",
       "26   0.108168  0.200589        8184.2               door        256     0.3   \n",
       "14   0.511027   1.11164       7981.57            dangers        256     0.2   \n",
       "40    0.62204   1.10993       5243.47         currencies        256     0.2   \n",
       "5   0.0785895  0.204033       8140.34           stencils        256     0.2   \n",
       "18    1.19579   1.14602       698.305          milligram         64     0.2   \n",
       "39   0.109621  0.198006       5485.84              ropes        256     0.3   \n",
       "36   0.176514  0.205003       2684.12               stop        128     0.2   \n",
       "13    1.07857   1.12236       2595.09           cleanser        128     0.3   \n",
       "22    0.19427  0.203925       2593.95          influence        128     0.3   \n",
       "32   0.984896   1.10634       1670.66             sparks        128     0.2   \n",
       "46   0.174754   0.19998       1767.04              color        128     0.2   \n",
       "9     1.29332   1.22162       1065.35           courtesy         64     0.2   \n",
       "2    0.200079  0.207182       2717.54             blasts        128     0.3   \n",
       "29  0.0850274  0.203961       8655.81            workman        256     0.2   \n",
       "3     1.24743    1.1673       673.535          occasions         64     0.3   \n",
       "19    1.18994   1.15157       689.051       extenuations         64     0.2   \n",
       "11   0.180696   0.20642        2540.7               gold        128     0.2   \n",
       "33   0.226623   0.21688       731.296             update         64     0.2   \n",
       "10   0.244774   0.22813       1118.41           neutrons         64     0.2   \n",
       "6     1.25189   1.17244       700.752      manufacturers         64     0.3   \n",
       "30   0.238675  0.219339       698.085              stars         64     0.3   \n",
       "4    0.236961    0.2174       728.228             boosts         64     0.3   \n",
       "45   0.228271  0.215703       700.107           thirteen         64     0.2   \n",
       "12    1.32786    1.2508       1064.19         objectives         64     0.2   \n",
       "27    1.42453   1.28034       1070.94          submarine         64     0.3   \n",
       "41   0.261387  0.234265       1074.27        acquisition         64     0.3   \n",
       "43   0.242749   0.22886        1064.7            morning         64     0.2   \n",
       "16     1.4138   1.26612       1053.15           thermals         64     0.3   \n",
       "7    0.260641  0.234228       1097.59          exercises         64     0.3   \n",
       "\n",
       "   lstm_layers      single_loss_function  multi_loss_function optimiser  \\\n",
       "37           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "38           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "15           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "47           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "0            2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "34           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "23           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "35           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "8            2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "1            3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "28           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "24           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "17           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "20           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "31           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "25           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "42           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "21           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "44           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "26           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "14           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "40           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "5            3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "18           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "39           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "36           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "13           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "22           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "32           2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "46           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "9            3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "2            3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "29           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "3            2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "19           2  categorical_crossentropy  binary_crossentropy      adam   \n",
       "11           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "33           2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "10           3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "6            2  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "30           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "4            2    categorical_focal_loss  binary_crossentropy      adam   \n",
       "45           2    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "12           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "27           3  categorical_crossentropy  binary_crossentropy   rmsprop   \n",
       "41           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "43           3    categorical_focal_loss  binary_crossentropy   rmsprop   \n",
       "16           3  categorical_crossentropy  binary_crossentropy      adam   \n",
       "7            3    categorical_focal_loss  binary_crossentropy      adam   \n",
       "\n",
       "   epochs last_layer_inputs test_loss_loss test_loss_categorical_accuracy  \\\n",
       "37     60             False          1.181                        0.67796   \n",
       "38     60             False        1.16788                       0.675354   \n",
       "15     60             False        1.15288                       0.684289   \n",
       "47     60             False        1.15728                       0.664929   \n",
       "0      60             False       0.212126                       0.665302   \n",
       "34     60             False        1.18782                       0.664557   \n",
       "23     60             False       0.218377                       0.658972   \n",
       "35     60             False        1.15275                       0.665302   \n",
       "8      60             False       0.212569                       0.658228   \n",
       "1      60             False         1.2495                         0.6586   \n",
       "28     60             False       0.217582                       0.655249   \n",
       "24     60             False        1.18807                       0.663812   \n",
       "17     60             False        1.17482                       0.664557   \n",
       "20     60             False        1.15033                       0.658972   \n",
       "31     60             False        1.17304                       0.658972   \n",
       "25     60             False       0.221225                       0.654133   \n",
       "42     60             False       0.218664                       0.655622   \n",
       "21     60             False       0.212168                       0.655622   \n",
       "44     60             False        1.16542                       0.657111   \n",
       "26     60             False        0.21728                       0.654505   \n",
       "14     60             False        1.29186                       0.650037   \n",
       "40     60             False        1.20454                       0.662323   \n",
       "5      60             False       0.227899                       0.648548   \n",
       "18     60             False        1.19956                       0.656739   \n",
       "39     60             False       0.210654                       0.663068   \n",
       "36     60             False       0.213148                       0.650037   \n",
       "13     60             False        1.17487                       0.650782   \n",
       "22     60             False       0.219316                       0.654877   \n",
       "32     60             False        1.16172                       0.656366   \n",
       "46     60             False       0.212857                       0.654133   \n",
       "9      60             False        1.26739                       0.650037   \n",
       "2      60             False       0.218776                       0.654133   \n",
       "29     60             False       0.221153                       0.661579   \n",
       "3      60             False        1.22061                       0.650782   \n",
       "19     60             False        1.20485                       0.652271   \n",
       "11     60             False       0.216906                       0.652271   \n",
       "33     60             False       0.227786                       0.651526   \n",
       "10     60             False       0.239131                       0.650782   \n",
       "6      60             False        1.22251                       0.650782   \n",
       "30     60             False       0.231233                        0.65041   \n",
       "4      60             False        0.22901                       0.645197   \n",
       "45     60             False       0.230626                       0.647431   \n",
       "12     60             False        1.30223                       0.646314   \n",
       "27     60             False        1.32622                       0.644453   \n",
       "41     60             False       0.248055                       0.641847   \n",
       "43     60             False       0.239254                       0.645197   \n",
       "16     60             False        1.31771                       0.641474   \n",
       "7      60             False       0.245478                       0.637007   \n",
       "\n",
       "   test_val_loss_loss test_val_loss_categorical_accuracy  \n",
       "37            1.12957                           0.670514  \n",
       "38            1.13248                           0.670141  \n",
       "15            1.13296                           0.667908  \n",
       "47            1.15651                           0.665674  \n",
       "0            0.212126                           0.665302  \n",
       "34            1.14598                           0.663068  \n",
       "23           0.209289                           0.662323  \n",
       "35             1.1604                           0.661579  \n",
       "8            0.212747                           0.661206  \n",
       "1              1.1555                           0.661206  \n",
       "28           0.212273                           0.660834  \n",
       "24            1.15028                           0.659717  \n",
       "17             1.1881                           0.659345  \n",
       "20            1.15033                           0.658972  \n",
       "31            1.17304                           0.658972  \n",
       "25           0.208333                           0.658972  \n",
       "42           0.210448                             0.6586  \n",
       "21           0.210386                           0.658228  \n",
       "44            1.17307                           0.657483  \n",
       "26           0.211745                           0.657483  \n",
       "14            1.15993                           0.656739  \n",
       "40            1.15853                           0.656739  \n",
       "5            0.211575                           0.656366  \n",
       "18            1.20371                           0.656366  \n",
       "39           0.205984                           0.655994  \n",
       "36           0.212067                           0.655249  \n",
       "13            1.17523                           0.654877  \n",
       "22           0.218716                           0.654505  \n",
       "32            1.16006                           0.654505  \n",
       "46           0.212857                           0.654133  \n",
       "9             1.26313                           0.654133  \n",
       "2            0.218776                           0.654133  \n",
       "29           0.211517                           0.653388  \n",
       "3             1.21874                           0.652271  \n",
       "19            1.20485                           0.652271  \n",
       "11           0.218087                           0.652271  \n",
       "33           0.227786                           0.651526  \n",
       "10           0.239131                           0.650782  \n",
       "6             1.22251                           0.650782  \n",
       "30           0.231233                            0.65041  \n",
       "4            0.228509                           0.649293  \n",
       "45           0.230025                           0.648176  \n",
       "12            1.30223                           0.646314  \n",
       "27            1.32622                           0.644453  \n",
       "41           0.248894                           0.644453  \n",
       "43           0.239271                           0.644453  \n",
       "16            1.31771                           0.641474  \n",
       "7             0.24638                           0.639613  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results.sort_values([\"test_val_loss_categorical_accuracy\"], ascending=False, inplace=True)\n",
    "df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['loss_epoch', 'val_loss_epoch', 'Note_o_categorical_accuracy',\n",
       "       'Dynamic_o_categorical_accuracy', 'TextExpression_o_binary_accuracy',\n",
       "       'Articulation_o_binary_accuracy', 'Spanner_o_binary_accuracy',\n",
       "       'Slur_o_binary_accuracy', 'val_Note_o_categorical_accuracy',\n",
       "       'val_Dynamic_o_categorical_accuracy',\n",
       "       'val_TextExpression_o_binary_accuracy',\n",
       "       'val_Articulation_o_binary_accuracy', 'val_Spanner_o_binary_accuracy',\n",
       "       'val_Slur_o_binary_accuracy', 'loss', 'Note_o_loss', 'Dynamic_o_loss',\n",
       "       'TextExpression_o_loss', 'Articulation_o_loss', 'Spanner_o_loss',\n",
       "       'Slur_o_loss', 'val_loss', 'val_Note_o_loss', 'val_Dynamic_o_loss',\n",
       "       'val_TextExpression_o_loss', 'val_Articulation_o_loss',\n",
       "       'val_Spanner_o_loss', 'val_Slur_o_loss', 'training_time',\n",
       "       'folder_name_prefix', 'lstm_units', 'dropout', 'lstm_layers',\n",
       "       'single_loss_function', 'multi_loss_function', 'optimiser', 'epochs',\n",
       "       'last_layer_inputs', 'test_loss_loss', 'test_loss_Note_o_loss',\n",
       "       'test_loss_Dynamic_o_loss', 'test_loss_TextExpression_o_loss',\n",
       "       'test_loss_Articulation_o_loss', 'test_loss_Spanner_o_loss',\n",
       "       'test_loss_Slur_o_loss', 'test_loss_Note_o_categorical_accuracy',\n",
       "       'test_loss_Dynamic_o_categorical_accuracy',\n",
       "       'test_loss_TextExpression_o_binary_accuracy',\n",
       "       'test_loss_Articulation_o_binary_accuracy',\n",
       "       'test_loss_Spanner_o_binary_accuracy',\n",
       "       'test_loss_Slur_o_binary_accuracy', 'test_val_loss_loss',\n",
       "       'test_val_loss_Note_o_loss', 'test_val_loss_Dynamic_o_loss',\n",
       "       'test_val_loss_TextExpression_o_loss',\n",
       "       'test_val_loss_Articulation_o_loss', 'test_val_loss_Spanner_o_loss',\n",
       "       'test_val_loss_Slur_o_loss',\n",
       "       'test_val_loss_Note_o_categorical_accuracy',\n",
       "       'test_val_loss_Dynamic_o_categorical_accuracy',\n",
       "       'test_val_loss_TextExpression_o_binary_accuracy',\n",
       "       'test_val_loss_Articulation_o_binary_accuracy',\n",
       "       'test_val_loss_Spanner_o_binary_accuracy',\n",
       "       'test_val_loss_Slur_o_binary_accuracy'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_results = df_test_results[['multi_loss_function', 'last_layer_inputs', 'test_val_loss_Note_o_categorical_accuracy', 'test_val_loss_Slur_o_binary_accuracy', 'test_val_loss_Dynamic_o_categorical_accuracy', 'test_val_loss_Spanner_o_binary_accuracy', 'test_val_loss_TextExpression_o_binary_accuracy', 'test_val_loss_Articulation_o_binary_accuracy']\n",
    "                                 \n",
    "                                 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\begin{tabular}{llllllll}\\n\\\\toprule\\n multi\\\\_loss\\\\_function & last\\\\_layer\\\\_inputs & test\\\\_val\\\\_loss\\\\_Note\\\\_o\\\\_categorical\\\\_accuracy & test\\\\_val\\\\_loss\\\\_Slur\\\\_o\\\\_binary\\\\_accuracy & test\\\\_val\\\\_loss\\\\_Dynamic\\\\_o\\\\_categorical\\\\_accuracy & test\\\\_val\\\\_loss\\\\_Spanner\\\\_o\\\\_binary\\\\_accuracy & test\\\\_val\\\\_loss\\\\_TextExpression\\\\_o\\\\_binary\\\\_accuracy & test\\\\_val\\\\_loss\\\\_Articulation\\\\_o\\\\_binary\\\\_accuracy \\\\\\\\\\n\\\\midrule\\n binary\\\\_crossentropy &             False &                                  0.971705 &                             0.999628 &                                     0.999628 &                                       1 &                                       0.999714 &                                     0.999894 \\\\\\\\\\n binary\\\\_crossentropy &              True &                                   0.77513 &                             0.991809 &                                     0.997022 &                                0.996091 &                                       0.998969 &                                     0.998511 \\\\\\\\\\n   binary\\\\_focal\\\\_loss &             False &                                  0.762844 &                                    1 &                                            1 &                                       1 &                                              1 &                                            1 \\\\\\\\\\n   binary\\\\_focal\\\\_loss &              True &                                  0.526061 &                                    1 &                                     0.998883 &                                       1 &                                              1 &                                            1 \\\\\\\\\\n\\\\bottomrule\\n\\\\end{tabular}\\n'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_results.to_latex(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
